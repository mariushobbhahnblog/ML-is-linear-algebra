---
layout:     post
title:      "What is the ML Projects blog about?"
subtitle:   "In this post I will give context about the kinds of projects I will present and in which way"
date:       2019-10-12 20:28:00
author:     "Marius Hobbhahn"
header-img: "img/marius2.jpg"
category:   ML_project
tags:       [machine learning]
---

# What is this ML Projects part about?

As a researcher I think it is quite natural that you want to present your projects to a wider audience of people. It is not only emotionally rewarding but it is also useful to have a profile that potential employers or PhD supervisors can see. And the latter is definetly a reason for the existence of this blog. But while a LinkedIn profile or just a short CV can also have the same benefits, there are some advantages of a blog that none of the other platforms have. Therefore I wanna summarize what I concider the most important purposes of this part of the blog in the following:

1. More **understandable style**: If somebody wanted to know something about a project they could obviously just go to arxiv and download the pdf or I could sent them the report if it is not published. However these papers and reports are not always easy to understand and optimized for someone who is already very familiar with the field. I guess most scientists have already read a paper that contained 30 references in the introduction where each of them was a one sentence summary of an entire subfield of research. While this is definetly a good system within the researchers individual community it is often frustrating for someone entering the field or just looking for a general overview. My focus in these blogposts is mainly on the bigger picture and less on the nasty details of a project. If you are interested in the details the link to the full report with all exceptions and numbers is still provided as well as the code. Just to give an example: I sometimes read a paragraph of a paper for multiple hours, looking through all the references trying to understand what the author was saying until I realized they said something along the lines of: "if we increase X then metric Y gets better but there are some exceptions" and all the complicated stuff I did not understand was just an elaborated analysis of the exceptions. In this blog in such cases I aim to just say: "if we increase X then metric Y gets better. There are some exceptions, if you care about them read the paper.", if those exceptions are not necessary to understand the bigger picture. 

2. More **honest way of writing**: I think the current norm of publishing is not one of radical honesty. While most researcher have good intentions and want to further their field as a whole they still care about recognition or funding which is often based on successfully publishing papers on big conferences. The vast majority of researchers does not p-hack or cheat to get good results but the truth gets bent a bit to make a result look more spectacular. For example if the new algorithm is better than reasonable comparisons on 2 of 7 datasets the author might try to justify in retrospect (i.e. after knowing the result) why these 2 datasets are more important than the other 5 to increase the value of their new algorithm. It's not technically cheating or lying but that person does not follow the standard procedure of establishing falsifiable hypotheses in advance. In some cases this behaviour can also be justified. Maybe you understand something only after working with the algorithm for multiple months and now realize why these datasets are more important than the others. I am also now angle with regards to this. As soon as some people overhype their results a bit and get more recognition than others they have a competitive advantage in the publication space where recognition is the limited resource is the thing everybody wants to have. Others follow and copy the strategy establishing a norm that is hard to break because it is a multi agent coordination problem which are generally very hard to solve. My aim for the posts in this blog are to be very direct and honest about my assessment of a project that I have been working on. If I think the project was great and has a lot of potential I will say so. If I think it is a nieche application that has some upsides and some downsides I will not sell it as a revolutionary idea. If I think the project was an utter failure and the algorithms have no right to get any further research I will also say it. However, if a project just doesn't yield any insight I will not write a paper or blog post about it. Maybe in some rare occasions I will write a blog post about a failure case which might have some insights for others but this will probably not be the norm. 

3. **Smaller projects**: Some projects are too small to write a paper about it but still add value to the research community. This might be a small but efficient and nicely documented piece of code, a proof that has some insights or just a smaller case study. I think a blog post is a good way to share these insights with others and will post them from time to time. 

##### One last note:
If you have any feedback regarding anything (i.e. layout, code or opinions) I would be grateful if you told me. Constructive criticism is prefered. 
